{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12049142,"sourceType":"datasetVersion","datasetId":7582857},{"sourceId":12049910,"sourceType":"datasetVersion","datasetId":7583419}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ancient to Modern Italian Translation with TinyLLaMA and BLOOMZ\n\nThis notebook compares two approaches for translating ancient Italian into modern Italian:\n\n1. **TinyLLaMA (Fine-tuned locally on parallel examples)**\n2. **BLOOMZ (Zero-shot / Few-shot Inference)**\n\n---\n\n## 🔧 Setup","metadata":{}},{"cell_type":"code","source":"# --- 1. Install required libraries ---\n!pip install -q transformers datasets peft bitsandbytes accelerate evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T15:33:11.409080Z","iopub.execute_input":"2025-06-04T15:33:11.409363Z","iopub.status.idle":"2025-06-04T15:34:49.620090Z","shell.execute_reply.started":"2025-06-04T15:33:11.409340Z","shell.execute_reply":"2025-06-04T15:34:49.619366Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- 2. Import modules ---\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import (\n    AutoTokenizer, AutoModelForCausalLM,\n    TrainingArguments, Trainer,\n    DataCollatorForLanguageModeling, BitsAndBytesConfig\n)\nfrom datasets import Dataset\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom sklearn.model_selection import train_test_split\nimport evaluate\nimport ast\n\n# --- 3. Load and prepare dataset ---\ndf = pd.read_csv('/kaggle/input/datasets-both/dataset_concatenato.csv')[['text', 'translation']].dropna()\ndf = df.rename(columns={'text': 'ancient', 'translation': 'modern'})\ndf = df.head(200)  # for quick training/testing\n\ndef fix_list_string_to_sentence(text):\n    # Try to parse string list representation to python list\n    try:\n        tokens = ast.literal_eval(text)\n        if isinstance(tokens, list):\n            return \" \".join(tokens)\n    except:\n        pass\n    return text  # fallback if parsing fails\n\ndf['modern'] = df['modern'].apply(fix_list_string_to_sentence)\n\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n\ntrain_ds = Dataset.from_pandas(train_df)\nval_ds = Dataset.from_pandas(val_df)\n\n# --- 4. Load tokenizer and model (4-bit quantized TinyLLaMA) ---\nmodel_id = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\nmodel = prepare_model_for_kbit_training(model)\n\n# --- 5. Apply LoRA ---\npeft_config = LoraConfig(\n    r = 16,\n    lora_alpha = 64,\n    lora_dropout = 0.1, target_modules=[\"q_proj\", \"v_proj\"],\n    bias=\"none\", task_type=\"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, peft_config)\n\n# --- 6. Preprocess: tokenize and mask input (prompt-only tuning) ---\ndef preprocess_function(examples):\n    prompts = [f\"Translate from ancient to modern Italian:\\nAncient: {a}\\nModern: {m}{tokenizer.eos_token}\" for a, m in zip(examples['ancient'], examples['modern'])]\n    return tokenizer(prompts, truncation=True, padding=\"max_length\", max_length=256)\n\ntrain_ds = train_ds.map(preprocess_function, batched=True, remove_columns=train_ds.column_names)\nval_ds = val_ds.map(preprocess_function, batched=True, remove_columns=val_ds.column_names)\n\n# --- 7. Define training ---\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/tinyllama-ft\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,  # effective batch size = 8\n    num_train_epochs=10,\n    logging_steps=50,\n    eval_strategy='steps',\n    eval_steps=50,\n    save_strategy='epoch',\n    learning_rate=2e-4,\n    fp16=True,\n    report_to='none',\n    gradient_checkpointing=True,\n    warmup_steps=10,\n    weight_decay=0.01,\n    logging_dir=\"/kaggle/working/logs\"\n)\n\ndef clean_decoded_text(text):\n        text = text.strip()\n        if text.startswith(\"[\") and text.endswith(\"]\"):\n            text = text[1:-1]  # remove brackets\n        text = text.replace(\"'\", \"\")  # remove quotes\n        return text.strip()\n\nbleu_metric = evaluate.load(\"bleu\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    if isinstance(preds, np.ndarray) and preds.ndim == 3:\n        preds = np.argmax(preds, axis=-1)\n    if isinstance(preds, torch.Tensor):\n        preds = preds.detach().cpu().numpy()\n    if isinstance(labels, torch.Tensor):\n        labels = labels.detach().cpu().numpy()\n    \n    labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n    \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds = [pred.split(\"Modern:\")[-1].strip() for pred in decoded_preds]\n    decoded_labels = [label.split(\"Modern:\")[-1].strip() for label in decoded_labels]\n\n    pred_tokens = [pred.split() for pred in decoded_preds]\n    label_tokens = [label.split() for label in decoded_labels]\n\n    print(\"Sample prediction:\", decoded_preds[0])\n    print(\"Ground truth:\", decoded_labels[0])\n\n    result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"bleu\"]}\n\ntrainer = Trainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    compute_metrics=compute_metrics,\n    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n)\n\n# --- 8. Train the model ---\ntrainer.train()\n\n# --- 9. Load test set ---\ntest_df = pd.read_csv('/kaggle/input/dataset-true/dataset_human_eval.csv')[['Sentence', 'HumanEval']].dropna()\ntest_df = test_df.rename(columns={'Sentence': 'ancient', 'HumanEval': 'modern'})\n\n# --- 10. Inference with few-shot prompt ---\nfew_shot_prompt = \"\"\"Translate from ancient to modern Italian:\n\nAncient: O Deo, co’ mi par forte non so se lo sapete, con’ v’amo di bon core;\nModern: Oddio, come mi sembra difficile non so se lo sapete quanto vi amo;\n\nAncient: Apparve luce, che rendé splendore, che passao per li occhi e ’l cor ferìo, ond’io ne sono a tal condizïone;\nModern: Apparve una luce splendente, che passò per gli occhi e colpì il cuore, cosicché io sono in tale condizione;\n\nAncient: Per lo cammino ch'è sì aspro e forte, vado cercando sol la mia salute;\nModern: Per il cammino che è così duro e difficile, vado cercando soltanto la mia salvezza;\n\nAncient: {input}\nModern:\"\"\"\n\ndef generate_with_tinyllama(text):\n    prompt = few_shot_prompt.format(input=text)\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=128,\n        do_sample=False,     # ← deterministic (greedy) decoding\n        num_beams=4,         # ← beam search helps BLEU\n        temperature=0.7,        # moderate randomness\n        top_p=0.9,              # nucleus sampling\n        early_stopping=True,\n        eos_token_id=tokenizer.eos_token_id,\n        pad_token_id=tokenizer.pad_token_id\n    )\n    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    # Strip everything before the final \"Modern:\" to get clean output\n    return decoded.split(\"Modern:\")[-1].strip()\n\n# --- 11. Generate on test set ---\ntest_df['tinyllama_output'] = test_df['ancient'].apply(generate_with_tinyllama)\n\n# --- 12. Save predictions ---\ntest_df[['ancient', 'modern', 'tinyllama_output']].to_csv(\"/kaggle/working/tinyllama_predictions.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:41:35.096014Z","iopub.execute_input":"2025-06-04T17:41:35.096430Z","iopub.status.idle":"2025-06-04T17:51:47.161597Z","shell.execute_reply.started":"2025-06-04T17:41:35.096405Z","shell.execute_reply":"2025-06-04T17:51:47.161011Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/133 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b40c1d05d19543908ba45f3ff5f8e5ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc3d038510d943649be7a94189c00f09"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_35/3683008165.py:127: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [160/160 07:25, Epoch 9/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>3.248100</td>\n      <td>2.853111</td>\n      <td>0.128961</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.487300</td>\n      <td>2.813025</td>\n      <td>0.128175</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.195500</td>\n      <td>2.849160</td>\n      <td>0.134546</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Sample prediction: Io non soensovo souggare il m, terra, né non fure se l, non vedederlo sfavolre davutt'eorno, come un ferro cheantentecente;eso uscito dal fuoco;\nGround truth: Io non potei fissare il sole a lungo, ma neppure così poco da non vederlo sfavillare tutt'intorno, come un ferro incandescente appena uscito dal fuoco;\nSample prediction: Io non soensova souggare il suo, terra, né non rimure così tanto, far vedederlo sfavolre davuttaviaoreeorno, come un ferro cheantentecente;are escito dal fuoco;\nGround truth: Io non potei fissare il sole a lungo, ma neppure così poco da non vederlo sfavillare tutt'intorno, come un ferro incandescente appena uscito dal fuoco;\nSample prediction: Io non soegva souggare il suo, terra, né solo rimure così,, far vedederlo sfavolre davuttaviaoreunorno, come un ferro cheantentecente cheare escito dal fuoco;\nGround truth: Io non potei fissare il sole a lungo, ma neppure così poco da non vederlo sfavillare tutt'intorno, come un ferro incandescente appena uscito dal fuoco;\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from IPython.display import display\ndisplay(test_df[['ancient', 'modern', 'tinyllama_output']].head(30))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:52:19.053641Z","iopub.execute_input":"2025-06-04T17:52:19.054341Z","iopub.status.idle":"2025-06-04T17:52:19.063773Z","shell.execute_reply.started":"2025-06-04T17:52:19.054316Z","shell.execute_reply":"2025-06-04T17:52:19.063072Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                                                                                                                                      ancient  \\\n0        quella guerra ben fatta l' opera perché etc. Et dall' altra parte Aiaces era uno cavaliere franco e prode all' arme, di gran guisa, ma non era pieno di grande senno   \n1                                                                   crudele, e di tutte le colpe pigli vendetta, come dice la legge, ed a neuno cavaliere perdoni che pecchi.   \n2                                                                                                  Non d' altra forza d' animo fue ornato Ponzio Aufidiano, romano cavaliere.   \n3                                                 Se questo piace a tutti e se 'l tempo hae bisogno d'avere Pompeio per cavaliere e non per compagno, non riterrò più i fati.   \n4                                                                 Officio di questa arte pare che sia dicere appostatamente per fare credere, fine è far credere per lo dire.   \n5                                                           Ecco e larghi ventipiovoli caggiono delle risolute nebbie; e potresti credere che tutto il cielo cadesse nel mare   \n6   Però che or chi spererebbe quello che eziandio questi che non vogliono ancora credere in Cristo, già veggiono con noi, e perché nol possono negare, stridono colli denti.   \n7                                                                                                I vendimenti de' morti et le presure de' vivi fece la frode d'uno feroce re.   \n8                         Acciocché quegli, il quale ora per le sue gran reità è feroce e onorevole, egli d'ogni male afflitto e tormentato della impietà verso il mio padre.   \n9                                                                                                        Gli uomini spessamente a stare fermi nella bugia incontra la verità.   \n10                                                                                 Marco Cornelio ch'era de' dieci compagni, studiosamente  si riservò di parlare all'ultimo.   \n11                                                                                                                               cose ch'io sapeva che erano fatte in Italia.   \n12                                                                                                            Corbio nipote d' Ortensio menò sua vita più bassa e più viziosa   \n13                                                            Altressì uno amante chiamando merzé alla sua donna dice parole e ragioni molte, et ella si difende in suo dire.   \n14                                                                   Io mi ricordo (ch. 347) che essendo adirato scapigliai la mia donna. Ohi, quanti dì questa ira mi tolse!   \n15                                                                                                       colui del quale tu tti solevi dolere ch' era amante della tua donna;   \n16                                                                            Ma no sapeano già le nomora di coloro dela congiurazione, ché la donna no nominava già li nomi.   \n17                                    Creti?  Certo quand'elli si mosse, elli ti dixe: \"O fedele mia donna, fa' che in mio luogo ti sia racomandato il nostro hoste troiano\".   \n18                                    A Milano fue ripressa la malvagità d' una donna in simile bugìa, nel tempo medesimo di questo signore della republica, in questo modo:    \n\n                                                                                                                                                                    modern  \\\n0   Quella guerra fu condotta bene perchè etc. Dall’altra parte, Aiace era un cavaliere franco e valoroso nelle armi, di grande statura, ma non possedeva grande saggezza.   \n1                                                                           È crudele, e punisce ogni colpa come vuole la legge, e non perdona alcun cavaliere che sbagli.   \n2                                                                                                   Ponzio Aufidiano, cavaliere romano, non fu dotato di un animo diverso.   \n3                                      Se questo piace a tutti e se il tempo ha bisogno di avere Pompeo come cavaliere e non come compagno, non ostacolerò più il destino.   \n4                            Il compito di quest’arte sembra essere quello di parlare in modo adatto per convincere; lo scopo è far credere qualcosa attraverso le parole.   \n5                                                             Ecco che forti piogge scendono dalle dense nebbie; potresti pensare che tutto il cielo stia cadendo in mare.   \n6   Perché ora chi spererebbe ciò che anche quelli che non vogliono ancora credere in Cristo, già vedono insieme a noi, e poiché non lo possono negare, stringono i denti.   \n7                                                                                 Le vendite dei morti e le pressioni sui vivi furono opera dell’inganno di un re crudele.   \n8                            Così che colui, che ora è temuto e onorato per i suoi grandi delitti, sia tormentato da ogni male a causa della sua crudeltà verso mio padre.   \n9                                                                                                 Spesso gli uomini incontrano la verità mentre stanno fermi in una bugia.   \n10                                                                 Marco Cornelio, che era uno dei dieci compagni, si riservò di parlare per ultimo con grande attenzione.   \n11                                                                                                                              Cose che sapevo essere avvenute in Italia.   \n12                                                                                                         Corbio, nipote di Ortensio, visse una vita più bassa e viziosa.   \n13                                                 Così anche un innamorato, chiedendo pietà alla sua donna, pronuncia molte parole e motivi, e lei risponde difendendosi.   \n14                                                Ricordo che, essendo arrabbiato, scompigliai i capelli della mia donna. Ahimè, quanti giorni persi a causa di quell’ira!   \n15                                                                                                 Colui di cui ti lamentavi spesso perché era innamorato della tua donna;   \n16                                                                                Ma ancora non conoscevano i nomi dei cospiratori, perché la donna non li aveva rivelati.   \n17                                                            Credi? Certo, quando partì, ti disse: “O mia fedele donna, ti affido al mio posto il nostro ospite troiano”.   \n18             A Milano fu fermata la malvagità di una donna colpevole di una simile bugia, proprio durante il tempo di quel governatore della repubblica, in questo modo:   \n\n                                                                                                                                                                                                                               tinyllama_output  \n0                                                                                                   Questa guerra è stata fatta perché Etaces era un cavaliere coraggioso e profondo in pensiero, ma non era sufficientemente dotato per l'arma  \n1                                                                                                         cruenta, e di tutte le colpe che ho commesso pigno giudizio, come dice la legge, ed a un cavaliere perdono la pena per i miei pecchi.  \n2                                                                                                                                                                  Non d' alcuna forza d' animo fu adornato Ponzio Aufidiano, romano cavaliere;  \n3                                                                                                              Se questo piace a tutti e se il tempo ha bisogno di avere Pompeo come cavaliere e non come compagno, non riprenderò più i fatti.  \n4                                                                                                      L'arte di questa disciplina sembra essere quella di dare la parola corretta per far credere, c'è fine di fare credere per l'espressione.  \n5                                                                                                                              Ecco le ciglia delle nebbie che caggiano i ventopiovoli, e potresti credere che tutto il cielo cadesse nel mare;  \n6                                                                                                  Poiché chi spera di questo che non vogliono ancora credere in Cristo, già vedono con noi, e perché non possono negare, stridono colli denti.  \n7                                                                                                                                                                                                                     Il cammino della luce che  \n8                                                                                 Altrimenti quegli uomini che ora per le sue grandi reitte è feroce e onorevole, egli d'ogni malessentimento e tormento del suo pessimismo verso il mio padre.  \n9                                                                                                                                                                                   Apparve una luce splendente, che passò per gli occhi e colp  \n10                                                                                                                            Ora mi sembra che non sia soltanto la mia salute, ma anche la mia vita, che si muove in un cammino aspro e forte.  \n11                                                                                                                                                                                             cose che io conoscevo che erano fatte in Italia.  \n12                                                                             Corbio nipote di Ortensio menò la sua vita di più bassa e più viva.\\n\\nAfter the translation: Oddio, come mi sembra difficile non so se lo sapete quanto vi amo;  \n13                                                                                                                            Altressì un amante chiama l'altra donna mia, con le parole e con gli argomenti molte, ella difende in suo favore.  \n14                                                                                                                         Io ricordo (ch. 347) che era necessario scapolare la mia moglie. Ohi, tutti i giorni di questa furia mi hanno tolto!  \n15                                                                                                                                                                                      Questo cammino, che è così duro e difficile, mi fa sent  \n16  Ma non sapevano già i nomi delle creature della congiurazione, poiché la donna non nominava già i nomi di essi.\\n\\nAncient: Ma non sapevano già i nomi delle creature della congiurazione, poiché la donna non nominava già i nomi di essi.  \n17                                                                                                                                                                                                Creti? Sì, quando i loro corpi si muovono, el  \n18                                                                                                     Oddio, come mi sembra difficile non so se lo sapete quanto vi amo;\\n\\nOddio, come mi sembra difficile non so se lo sapete quanto vi amo;  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ancient</th>\n      <th>modern</th>\n      <th>tinyllama_output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quella guerra ben fatta l' opera perché etc. Et dall' altra parte Aiaces era uno cavaliere franco e prode all' arme, di gran guisa, ma non era pieno di grande senno</td>\n      <td>Quella guerra fu condotta bene perchè etc. Dall’altra parte, Aiace era un cavaliere franco e valoroso nelle armi, di grande statura, ma non possedeva grande saggezza.</td>\n      <td>Questa guerra è stata fatta perché Etaces era un cavaliere coraggioso e profondo in pensiero, ma non era sufficientemente dotato per l'arma</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>crudele, e di tutte le colpe pigli vendetta, come dice la legge, ed a neuno cavaliere perdoni che pecchi.</td>\n      <td>È crudele, e punisce ogni colpa come vuole la legge, e non perdona alcun cavaliere che sbagli.</td>\n      <td>cruenta, e di tutte le colpe che ho commesso pigno giudizio, come dice la legge, ed a un cavaliere perdono la pena per i miei pecchi.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Non d' altra forza d' animo fue ornato Ponzio Aufidiano, romano cavaliere.</td>\n      <td>Ponzio Aufidiano, cavaliere romano, non fu dotato di un animo diverso.</td>\n      <td>Non d' alcuna forza d' animo fu adornato Ponzio Aufidiano, romano cavaliere;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Se questo piace a tutti e se 'l tempo hae bisogno d'avere Pompeio per cavaliere e non per compagno, non riterrò più i fati.</td>\n      <td>Se questo piace a tutti e se il tempo ha bisogno di avere Pompeo come cavaliere e non come compagno, non ostacolerò più il destino.</td>\n      <td>Se questo piace a tutti e se il tempo ha bisogno di avere Pompeo come cavaliere e non come compagno, non riprenderò più i fatti.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Officio di questa arte pare che sia dicere appostatamente per fare credere, fine è far credere per lo dire.</td>\n      <td>Il compito di quest’arte sembra essere quello di parlare in modo adatto per convincere; lo scopo è far credere qualcosa attraverso le parole.</td>\n      <td>L'arte di questa disciplina sembra essere quella di dare la parola corretta per far credere, c'è fine di fare credere per l'espressione.</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Ecco e larghi ventipiovoli caggiono delle risolute nebbie; e potresti credere che tutto il cielo cadesse nel mare</td>\n      <td>Ecco che forti piogge scendono dalle dense nebbie; potresti pensare che tutto il cielo stia cadendo in mare.</td>\n      <td>Ecco le ciglia delle nebbie che caggiano i ventopiovoli, e potresti credere che tutto il cielo cadesse nel mare;</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Però che or chi spererebbe quello che eziandio questi che non vogliono ancora credere in Cristo, già veggiono con noi, e perché nol possono negare, stridono colli denti.</td>\n      <td>Perché ora chi spererebbe ciò che anche quelli che non vogliono ancora credere in Cristo, già vedono insieme a noi, e poiché non lo possono negare, stringono i denti.</td>\n      <td>Poiché chi spera di questo che non vogliono ancora credere in Cristo, già vedono con noi, e perché non possono negare, stridono colli denti.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>I vendimenti de' morti et le presure de' vivi fece la frode d'uno feroce re.</td>\n      <td>Le vendite dei morti e le pressioni sui vivi furono opera dell’inganno di un re crudele.</td>\n      <td>Il cammino della luce che</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Acciocché quegli, il quale ora per le sue gran reità è feroce e onorevole, egli d'ogni male afflitto e tormentato della impietà verso il mio padre.</td>\n      <td>Così che colui, che ora è temuto e onorato per i suoi grandi delitti, sia tormentato da ogni male a causa della sua crudeltà verso mio padre.</td>\n      <td>Altrimenti quegli uomini che ora per le sue grandi reitte è feroce e onorevole, egli d'ogni malessentimento e tormento del suo pessimismo verso il mio padre.</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Gli uomini spessamente a stare fermi nella bugia incontra la verità.</td>\n      <td>Spesso gli uomini incontrano la verità mentre stanno fermi in una bugia.</td>\n      <td>Apparve una luce splendente, che passò per gli occhi e colp</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Marco Cornelio ch'era de' dieci compagni, studiosamente  si riservò di parlare all'ultimo.</td>\n      <td>Marco Cornelio, che era uno dei dieci compagni, si riservò di parlare per ultimo con grande attenzione.</td>\n      <td>Ora mi sembra che non sia soltanto la mia salute, ma anche la mia vita, che si muove in un cammino aspro e forte.</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>cose ch'io sapeva che erano fatte in Italia.</td>\n      <td>Cose che sapevo essere avvenute in Italia.</td>\n      <td>cose che io conoscevo che erano fatte in Italia.</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Corbio nipote d' Ortensio menò sua vita più bassa e più viziosa</td>\n      <td>Corbio, nipote di Ortensio, visse una vita più bassa e viziosa.</td>\n      <td>Corbio nipote di Ortensio menò la sua vita di più bassa e più viva.\\n\\nAfter the translation: Oddio, come mi sembra difficile non so se lo sapete quanto vi amo;</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Altressì uno amante chiamando merzé alla sua donna dice parole e ragioni molte, et ella si difende in suo dire.</td>\n      <td>Così anche un innamorato, chiedendo pietà alla sua donna, pronuncia molte parole e motivi, e lei risponde difendendosi.</td>\n      <td>Altressì un amante chiama l'altra donna mia, con le parole e con gli argomenti molte, ella difende in suo favore.</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Io mi ricordo (ch. 347) che essendo adirato scapigliai la mia donna. Ohi, quanti dì questa ira mi tolse!</td>\n      <td>Ricordo che, essendo arrabbiato, scompigliai i capelli della mia donna. Ahimè, quanti giorni persi a causa di quell’ira!</td>\n      <td>Io ricordo (ch. 347) che era necessario scapolare la mia moglie. Ohi, tutti i giorni di questa furia mi hanno tolto!</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>colui del quale tu tti solevi dolere ch' era amante della tua donna;</td>\n      <td>Colui di cui ti lamentavi spesso perché era innamorato della tua donna;</td>\n      <td>Questo cammino, che è così duro e difficile, mi fa sent</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Ma no sapeano già le nomora di coloro dela congiurazione, ché la donna no nominava già li nomi.</td>\n      <td>Ma ancora non conoscevano i nomi dei cospiratori, perché la donna non li aveva rivelati.</td>\n      <td>Ma non sapevano già i nomi delle creature della congiurazione, poiché la donna non nominava già i nomi di essi.\\n\\nAncient: Ma non sapevano già i nomi delle creature della congiurazione, poiché la donna non nominava già i nomi di essi.</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Creti?  Certo quand'elli si mosse, elli ti dixe: \"O fedele mia donna, fa' che in mio luogo ti sia racomandato il nostro hoste troiano\".</td>\n      <td>Credi? Certo, quando partì, ti disse: “O mia fedele donna, ti affido al mio posto il nostro ospite troiano”.</td>\n      <td>Creti? Sì, quando i loro corpi si muovono, el</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>A Milano fue ripressa la malvagità d' una donna in simile bugìa, nel tempo medesimo di questo signore della republica, in questo modo:</td>\n      <td>A Milano fu fermata la malvagità di una donna colpevole di una simile bugia, proprio durante il tempo di quel governatore della repubblica, in questo modo:</td>\n      <td>Oddio, come mi sembra difficile non so se lo sapete quanto vi amo;\\n\\nOddio, come mi sembra difficile non so se lo sapete quanto vi amo;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"test_dataset = pd.read_csv('/kaggle/input/datasets-both/dataset_cleaned (1).csv')[['Sentence']].dropna()\ntest_dataset = test_dataset.rename(columns={'Sentence': 'ancient'})\n\ntest_dataset['tinyllama_output'] = test_dataset['ancient'].apply(generate_with_tinyllama)\ntest_dataset[['ancient', 'tinyllama_output']].to_csv(\"/kaggle/working/tinyllama_test_predictions.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T18:06:52.740151Z","iopub.execute_input":"2025-06-04T18:06:52.740463Z","iopub.status.idle":"2025-06-04T18:19:53.888981Z","shell.execute_reply.started":"2025-06-04T18:06:52.740442Z","shell.execute_reply":"2025-06-04T18:19:53.888418Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"}],"execution_count":32}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ancient to Modern Italian Translation with TinyLLaMA and BLOOMZ\n",
    "\n",
    "This notebook compares two approaches for translating ancient Italian into modern Italian:\n",
    "\n",
    "1. **TinyLLaMA (Fine-tuned locally on parallel examples)**\n",
    "2. **BLOOMZ (Zero-shot / Few-shot Inference)**\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T14:34:44.537211Z",
     "iopub.status.busy": "2025-06-06T14:34:44.536901Z",
     "iopub.status.idle": "2025-06-06T14:36:06.486222Z",
     "shell.execute_reply": "2025-06-06T14:36:06.485371Z",
     "shell.execute_reply.started": "2025-06-06T14:34:44.537186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# --- 1. Install required libraries ---\n",
    "!pip install -q transformers datasets peft bitsandbytes accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:05:01.921715Z",
     "iopub.status.busy": "2025-06-06T17:05:01.921410Z",
     "iopub.status.idle": "2025-06-06T17:37:22.013940Z",
     "shell.execute_reply": "2025-06-06T17:37:22.013106Z",
     "shell.execute_reply.started": "2025-06-06T17:05:01.921694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad6a8e0e4b0459689c80d76365c3c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/266 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e7acac41474e51bcb9f1ed62bf2772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/827959901.py:193: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with early stopping based on validation BLEU...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 28:41, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>2.738626</td>\n",
       "      <td>0.124567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.798400</td>\n",
       "      <td>2.665295</td>\n",
       "      <td>0.125582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.591300</td>\n",
       "      <td>2.590719</td>\n",
       "      <td>0.125710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.575800</td>\n",
       "      <td>2.531405</td>\n",
       "      <td>0.136007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.566000</td>\n",
       "      <td>2.467233</td>\n",
       "      <td>0.104028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.469900</td>\n",
       "      <td>2.410282</td>\n",
       "      <td>0.085793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.422900</td>\n",
       "      <td>2.369215</td>\n",
       "      <td>0.086277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.340800</td>\n",
       "      <td>2.336598</td>\n",
       "      <td>0.101537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.307700</td>\n",
       "      <td>2.308064</td>\n",
       "      <td>0.104296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.218300</td>\n",
       "      <td>2.280741</td>\n",
       "      <td>0.101310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.248400</td>\n",
       "      <td>2.260098</td>\n",
       "      <td>0.104807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.083600</td>\n",
       "      <td>2.244993</td>\n",
       "      <td>0.100523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.134200</td>\n",
       "      <td>2.226974</td>\n",
       "      <td>0.099435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.053300</td>\n",
       "      <td>2.212649</td>\n",
       "      <td>0.100634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.964600</td>\n",
       "      <td>2.211004</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.030400</td>\n",
       "      <td>2.202706</td>\n",
       "      <td>0.099889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.983500</td>\n",
       "      <td>2.184541</td>\n",
       "      <td>0.092258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.875800</td>\n",
       "      <td>2.182701</td>\n",
       "      <td>0.098146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.923000</td>\n",
       "      <td>2.181998</td>\n",
       "      <td>0.094832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.838100</td>\n",
       "      <td>2.174857</td>\n",
       "      <td>0.095911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.804700</td>\n",
       "      <td>2.176033</td>\n",
       "      <td>0.088132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.777100</td>\n",
       "      <td>2.183037</td>\n",
       "      <td>0.083499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.761100</td>\n",
       "      <td>2.184821</td>\n",
       "      <td>0.080402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.643200</td>\n",
       "      <td>2.184128</td>\n",
       "      <td>0.089024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.622000</td>\n",
       "      <td>2.190183</td>\n",
       "      <td>0.082553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.740300</td>\n",
       "      <td>2.202973</td>\n",
       "      <td>0.080699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.621900</td>\n",
       "      <td>2.205443</td>\n",
       "      <td>0.083529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.520900</td>\n",
       "      <td>2.213561</td>\n",
       "      <td>0.082722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.556400</td>\n",
       "      <td>2.222170</td>\n",
       "      <td>0.083451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.541800</td>\n",
       "      <td>2.230891</td>\n",
       "      <td>0.082297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.536500</td>\n",
       "      <td>2.228087</td>\n",
       "      <td>0.078996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.543500</td>\n",
       "      <td>2.248066</td>\n",
       "      <td>0.077622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.492100</td>\n",
       "      <td>2.258453</td>\n",
       "      <td>0.080173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.520600</td>\n",
       "      <td>2.245429</td>\n",
       "      <td>0.082279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.377400</td>\n",
       "      <td>2.252923</td>\n",
       "      <td>0.083011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>2.274719</td>\n",
       "      <td>0.081885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.458500</td>\n",
       "      <td>2.281739</td>\n",
       "      <td>0.081021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.382700</td>\n",
       "      <td>2.282723</td>\n",
       "      <td>0.077996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.331500</td>\n",
       "      <td>2.292552</td>\n",
       "      <td>0.078702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.350800</td>\n",
       "      <td>2.303637</td>\n",
       "      <td>0.078224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.334800</td>\n",
       "      <td>2.305219</td>\n",
       "      <td>0.079779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.287700</td>\n",
       "      <td>2.309941</td>\n",
       "      <td>0.078751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.253200</td>\n",
       "      <td>2.316901</td>\n",
       "      <td>0.078328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.341000</td>\n",
       "      <td>2.317718</td>\n",
       "      <td>0.078688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.326100</td>\n",
       "      <td>2.316946</td>\n",
       "      <td>0.078709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.293100</td>\n",
       "      <td>2.323843</td>\n",
       "      <td>0.077041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.235500</td>\n",
       "      <td>2.325835</td>\n",
       "      <td>0.076886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.312100</td>\n",
       "      <td>2.327773</td>\n",
       "      <td>0.077203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.220400</td>\n",
       "      <td>2.329235</td>\n",
       "      <td>0.077203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample prediction: d’ altro pesce in tutta la costaiera;p pescatori e navicelle a schiera,e barche,saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di’ altro pesce in tutta la costaiera;p pescatori e navicelle a schiera,e barche,saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di’ volta pesce in tutta la Riviera;p pescatori e navicelle a schiera,e barche,saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di’ volta pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di con volta pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di con volta pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di con pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di con pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: di di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: [' di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to English Greek modern Greek.\n",
      "\n",
      "che:\n",
      "ileacunoaltro,ce, cuita la terraol,\n",
      " leciati di conielle, borderm, che conca di eppini, baralee,cheModerno di di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for\n",
      "\n",
      "che:\n",
      "ileacunoaltraro,o, cuita la terraol,\n",
      " unciati di pesielle, borderm, che conca di eppini, baralee,cheModerno di di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for\n",
      "\n",
      "che:\n",
      "ileacunoaltraro,o, cuita la terraol,\n",
      " leciati di pesielle, borderm, che conca di eppini, baralee,cheModerno [' di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for\n",
      "\n",
      "che:\n",
      "ileacunoaltraro,ce, cuita la terraol,\n",
      " leciati di pesielle, borderm, che conca di eppini, baralee,cheModerno [' di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,ce, cuita la terraol,\n",
      " leciati di pesielle, borderm, che conca di eppini, baralee,cheModerno di di pes pesce in tutta la riviera; con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,ce, cuita la terraol,\n",
      " leciati e pesielle, borderm, che conca di eppini, baralee,cheModerno da di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,ce, cuita la terraol,\n",
      " leciati e pesielle, borderm, che conca di eppie, baralee,cheModerno da di pes pesce in tutta la riviera; con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, cuita la suaol,\n",
      " leciati e pesielle, borderm, che conca di eppate, galalee,cheModerno [' di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, cuita la suaol,\n",
      " leciati e pesielle, borderm, che conca dicheppate, galalee,cheModerno [' di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, cuita la suaol,\n",
      " leciati e pesielle, borderm, che conca dicheppate, baralee,cheModerno da di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, cuita la terraol,\n",
      " leciati e pesielle, borderm, che conca dicheppie, galalee,cheModerno [' di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, cuita la terraol,\n",
      " leciati e pesielle, borderm, che conca dicheppie, galalee,cheModerno da di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, cuita la terraol,\n",
      " leciati di pesielle, borderm, che conca dicheppate, galalee,cheModernoo [' di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, gradota la suaol,\n",
      " leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo [' di pes pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, gradota la suaol,\n",
      " leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, gradota la suaol,\n",
      " leciati e pesielle, borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, gradota la suaol,\n",
      " leciati e pesielle, borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera; con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, gradota la forol, e leciati e pesielle, borderm, che conca dicheppanti, galalee,cheModernoo [' di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, gradota la forol,\n",
      " leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek for \n",
      "che:\n",
      "ileacunoaltraro,o, gradota la forol,\n",
      " leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "che:\n",
      "ileacunoaltraro,o, gradota la suaol, e leciati e pesielle, borderm, che conca dicheppanti, galalee,cheModernoo [' di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "che:\n",
      "ileacunoaltraro,o, gradota la suaiera, e leciati e pesielle, borderm, che conca dicheppanti, galalee,cheModernoo [' di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "che:\n",
      "ileessunoaltraro,o, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,o, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,o, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo [' di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,are, gradota la suaiera, e leciati che pesielle che borderm, che conca dicheppanti, galalee,cheModernoo [' di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,are, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo [' di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,are, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,o, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,are, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,are, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,are, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Sample prediction: MITlate to Spanish Greek modern Greek and \n",
      "cient:\n",
      "ileessunoaltraro,are, gradota la suaiera, e leciati e pesielle che borderm, che conca dicheppanti, galalee,cheModernoo da di pes pesce nella tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Ground truth: e ogni altro pesce in tutta la riviera;con pescatori e navicelle a schiera,e barche, saettie e galeoni,\n",
      "Training finished. Best model (based on val BLEU) is loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Import modules ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer,\n",
    "    DataCollatorForLanguageModeling, BitsAndBytesConfig,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import ast\n",
    "\n",
    "# --- 3. Load and prepare dataset ---\n",
    "df = pd.read_csv('/kaggle/input/dataset-list/dataset_concatenato.csv')[['text', 'translation']].dropna()\n",
    "df = df.rename(columns={'text': 'ancient', 'translation': 'modern'})\n",
    "\n",
    "def fix_list_string_to_sentence(text):\n",
    "    # Try to parse string list representation to python list\n",
    "    try:\n",
    "        tokens = ast.literal_eval(text)\n",
    "        if isinstance(tokens, list):\n",
    "            return \" \".join(tokens)\n",
    "    except:\n",
    "        pass\n",
    "    return text  # fallback if parsing fails\n",
    "\n",
    "df['ancient'] = df['ancient'].apply(fix_list_string_to_sentence)\n",
    "df['modern'] = df['modern'].apply(fix_list_string_to_sentence)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(val_df)\n",
    "\n",
    "# --- 4. Load tokenizer and model (4-bit quantized TinyLLaMA) ---\n",
    "model_id = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# --- 5. Apply LoRA ---\n",
    "TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32, # Often r*2\n",
    "    lora_dropout=0.05, # Slightly lower\n",
    "    target_modules=TARGET_MODULES,\n",
    "    bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# --- 6. Preprocess: tokenize and MASK input for focused learning ---\n",
    "def preprocess_function_with_masking(examples):\n",
    "    # Construct the full input string that the model will see for generation\n",
    "    # Model will be prompted with: \"Translate...\\nAncient: {a}\\nModern:\"\n",
    "    # And it should generate: \"{m}{eos_token}\"\n",
    "    \n",
    "    prompts_with_targets = []\n",
    "    prompts_only_for_masking = []\n",
    "\n",
    "    for ancient, modern in zip(examples['ancient'], examples['modern']):\n",
    "        # This is the full sequence for training input_ids\n",
    "        text = f\"Translate from ancient to modern Italian:\\nAncient: {ancient}\\nModern: {modern}{tokenizer.eos_token}\"\n",
    "        prompts_with_targets.append(text)\n",
    "        \n",
    "        # This is the part we want to MASK in the labels\n",
    "        prompt_part = f\"Translate from ancient to modern Italian:\\nAncient: {ancient}\\nModern:\"\n",
    "        prompts_only_for_masking.append(prompt_part)\n",
    "\n",
    "    # Tokenize the full sequences (prompt + target)\n",
    "    model_inputs = tokenizer(\n",
    "        prompts_with_targets,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256, # Your MAX_LENGTH\n",
    "        # return_tensors=\"pt\" # Not needed if Trainer handles it\n",
    "    )\n",
    "\n",
    "    # Create labels and mask the prompt part\n",
    "    labels = []\n",
    "    for i in range(len(model_inputs[\"input_ids\"])):\n",
    "        input_ids_example = model_inputs[\"input_ids\"][i]\n",
    "        \n",
    "        # Tokenize the prompt_only part to find its length *within the context of the full tokenized sequence*\n",
    "        # Important: tokenize prompts_only_for_masking[i] *without* adding special tokens like BOS,\n",
    "        # as BOS is already part of model_inputs[\"input_ids\"][i] if the tokenizer adds it.\n",
    "        prompt_tokens = tokenizer.encode(prompts_only_for_masking[i], add_special_tokens=False)\n",
    "        prompt_length = len(prompt_tokens)\n",
    "        \n",
    "        # Account for BOS token if tokenizer adds it to the beginning of the full sequence\n",
    "        actual_mask_length = prompt_length\n",
    "        if tokenizer.bos_token_id is not None and input_ids_example[0] == tokenizer.bos_token_id:\n",
    "            actual_mask_length +=1 # The BOS token is part of the \"context\" to be masked\n",
    "\n",
    "        # Create a copy of input_ids for labels\n",
    "        label_example = list(input_ids_example)\n",
    "        \n",
    "        # Mask the prompt part by setting tokens to -100\n",
    "        for j in range(actual_mask_length):\n",
    "            label_example[j] = -100\n",
    "            \n",
    "        # Also ensure padding tokens in the target part are -100\n",
    "        for j in range(actual_mask_length, len(label_example)):\n",
    "            if label_example[j] == tokenizer.pad_token_id:\n",
    "                label_example[j] = -100\n",
    "        \n",
    "        labels.append(label_example)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# Apply the new preprocessing function\n",
    "train_ds = train_ds.map(preprocess_function_with_masking, batched=True, remove_columns=train_ds.column_names)\n",
    "val_ds = val_ds.map(preprocess_function_with_masking, batched=True, remove_columns=val_ds.column_names)\n",
    "\n",
    "# --- 7. Define training ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/tinyllama-ft\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=15,  # Reduced epochs, rely on early stopping\n",
    "    logging_steps=10,     # Log more frequently if dataset is small\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=10,        # Evaluate more frequently if dataset is small\n",
    "    save_strategy='steps',\n",
    "    save_steps=10,        # Save more frequently, tied to eval_steps\n",
    "    learning_rate=2e-5,   # Adjusted learning rate\n",
    "    # fp16=True, # Not strictly necessary with bnb_config.bnb_4bit_compute_dtype\n",
    "    report_to='none',\n",
    "    gradient_checkpointing=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"/kaggle/working/logs\",\n",
    "    load_best_model_at_end=True,    # Crucial for preventing overfitting\n",
    "    metric_for_best_model=\"bleu\", # Monitor BLEU on validation set\n",
    "    greater_is_better=True,       # For BLEU, higher is better\n",
    "    save_total_limit=3            # Keep best, last, and maybe one more\n",
    ")\n",
    "\n",
    "def clean_decoded_text(text):\n",
    "        text = text.strip()\n",
    "        if text.startswith(\"[\") and text.endswith(\"]\"):\n",
    "            text = text[1:-1]  # remove brackets\n",
    "        text = text.replace(\"'\", \"\")  # remove quotes\n",
    "        return text.strip()\n",
    "\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    if isinstance(preds, np.ndarray) and preds.ndim == 3:\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "    if isinstance(preds, torch.Tensor):\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "    \n",
    "    labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "    \n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_preds = [pred.split(\"Modern:\")[-1].strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.split(\"Modern:\")[-1].strip() for label in decoded_labels]\n",
    "\n",
    "    pred_tokens = [pred.split() for pred in decoded_preds]\n",
    "    label_tokens = [label.split() for label in decoded_labels]\n",
    "\n",
    "    print(\"Sample prediction:\", decoded_preds[0])\n",
    "    print(\"Ground truth:\", decoded_labels[0])\n",
    "\n",
    "    result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"bleu\"]}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics, # This is fine for monitoring with argmax\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=\"longest\")\n",
    ")\n",
    "\n",
    "# --- 8. Train the model ---\n",
    "print(\"Starting training with early stopping based on validation BLEU...\")\n",
    "trainer.train()\n",
    "print(\"Training finished. Best model (based on val BLEU) is loaded.\")\n",
    "\n",
    "# --- 9. Load test set ---\n",
    "test_df = pd.read_csv('/kaggle/input/dataset-list/dataset_human_eval.csv')[['Sentence', 'HumanEval']].dropna()\n",
    "test_df = test_df.rename(columns={'Sentence': 'ancient', 'HumanEval': 'modern'})\n",
    "\n",
    "# --- 10. Inference with zero-shot prompt ---\n",
    "zero_shot_prompt = \"\"\"Translate from ancient to modern Italian:\n",
    "Ancient: {input}\n",
    "Modern:\"\"\"\n",
    "\n",
    "def generate_with_tinyllama(text):\n",
    "    prompt = zero_shot_prompt.format(input=text)\n",
    "    MAX_INPUT_PROMPT_LENGTH = 256 - 128 # max_length_train - max_new_tokens\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_INPUT_PROMPT_LENGTH).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"], # More explicit\n",
    "        attention_mask=inputs[\"attention_mask\"], # Pass attention_mask\n",
    "        max_new_tokens=128,\n",
    "        do_sample=False,\n",
    "        num_beams=4,\n",
    "        early_stopping=True, # Good\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id # Ensure this is correctly set\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Strip everything before the final \"Modern:\" to get clean output\n",
    "    return decoded.split(\"Modern:\")[-1].strip()\n",
    "\n",
    "# --- 11. Generate on test set ---\n",
    "test_df['tinyllama_output'] = test_df['ancient'].apply(generate_with_tinyllama)\n",
    "\n",
    "# --- 12. Save predictions ---\n",
    "test_df[['ancient', 'modern', 'tinyllama_output']].to_csv(\"/kaggle/working/tinyllama_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T16:41:55.887080Z",
     "iopub.status.busy": "2025-06-06T16:41:55.886722Z",
     "iopub.status.idle": "2025-06-06T16:41:55.898686Z",
     "shell.execute_reply": "2025-06-06T16:41:55.897965Z",
     "shell.execute_reply.started": "2025-06-06T16:41:55.887031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ancient</th>\n",
       "      <th>modern</th>\n",
       "      <th>tinyllama_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quella guerra ben fatta l' opera perché etc. E...</td>\n",
       "      <td>Quella guerra fu condotta bene perchè etc. Dal...</td>\n",
       "      <td>la guerra che è stata effettivamente compiuta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crudele, e di tutte le colpe pigli vendetta, c...</td>\n",
       "      <td>È crudele, e punisce ogni colpa come vuole la ...</td>\n",
       "      <td>crudele, e di tutte le colpe pigli vendetta, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non d' altra forza d' animo fue ornato Ponzio ...</td>\n",
       "      <td>Ponzio Aufidiano, cavaliere romano, non fu dot...</td>\n",
       "      <td>Non d' altra forza d' animo fu ornato Ponzio A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Se questo piace a tutti e se 'l tempo hae biso...</td>\n",
       "      <td>Se questo piace a tutti e se il tempo ha bisog...</td>\n",
       "      <td>Se questo piace a tutti e se 'l tempo hae biso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Officio di questa arte pare che sia dicere app...</td>\n",
       "      <td>Il compito di quest’arte sembra essere quello ...</td>\n",
       "      <td>L'ufficio di questa arte sembra essere dichiar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ecco e larghi ventipiovoli caggiono delle riso...</td>\n",
       "      <td>Ecco che forti piogge scendono dalle dense neb...</td>\n",
       "      <td>Ecco e larghi ventipiovoli caggiono delle riso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Però che or chi spererebbe quello che eziandio...</td>\n",
       "      <td>Perché ora chi spererebbe ciò che anche quelli...</td>\n",
       "      <td>Because they do not want to believe in Christ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I vendimenti de' morti et le presure de' vivi ...</td>\n",
       "      <td>Le vendite dei morti e le pressioni sui vivi f...</td>\n",
       "      <td>I vendimenti de' morti et le presure de' vivi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acciocché quegli, il quale ora per le sue gran...</td>\n",
       "      <td>Così che colui, che ora è temuto e onorato pe...</td>\n",
       "      <td>Quegli, il quale ora è feroce e onorevole per ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gli uomini spessamente a stare fermi nella bug...</td>\n",
       "      <td>Spesso gli uomini incontrano la verità mentre ...</td>\n",
       "      <td>Gli uomini stanno fermi nella bugia incontrand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Marco Cornelio ch'era de' dieci compagni, stud...</td>\n",
       "      <td>Marco Cornelio, che era uno dei dieci compagni...</td>\n",
       "      <td>Marco Cornelio, que era de diez compañeros, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cose ch'io sapeva che erano fatte in Italia.</td>\n",
       "      <td>Cose che sapevo essere avvenute in Italia.</td>\n",
       "      <td>cose che io conosco che sono state fatte in It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Corbio nipote d' Ortensio menò sua vita più ba...</td>\n",
       "      <td>Corbio, nipote di Ortensio, visse una vita più...</td>\n",
       "      <td>Corbio nipote d'Ortensio menò la sua vita più ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Altressì uno amante chiamando merzé alla sua d...</td>\n",
       "      <td>Così anche un innamorato, chiedendo pietà alla...</td>\n",
       "      <td>Altressì uno amante chiamando merzé alla sua d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Io mi ricordo (ch. 347) che essendo adirato sc...</td>\n",
       "      <td>Ricordo che, essendo arrabbiato, scompigliai i...</td>\n",
       "      <td>Io mi ricordo (ch. 347) che essendo furioso sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>colui del quale tu tti solevi dolere ch' era a...</td>\n",
       "      <td>Colui di cui ti lamentavi spesso perché era in...</td>\n",
       "      <td>Your lover, who was in love with your wife.\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ma no sapeano già le nomora di coloro dela con...</td>\n",
       "      <td>Ma ancora non conoscevano i nomi dei cospirato...</td>\n",
       "      <td>Ma non sapevano già le nomi delle donne della ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Creti?  Certo quand'elli si mosse, elli ti dix...</td>\n",
       "      <td>Credi? Certo, quando partì, ti disse: “O mia f...</td>\n",
       "      <td>Credi che io sia fedele alla tua moglie, ti di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A Milano fue ripressa la malvagità d' una donn...</td>\n",
       "      <td>A Milano fu fermata la malvagità di una donna ...</td>\n",
       "      <td>A Milano è stata ripristinata la malvagità di ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ancient  \\\n",
       "0   quella guerra ben fatta l' opera perché etc. E...   \n",
       "1   crudele, e di tutte le colpe pigli vendetta, c...   \n",
       "2   Non d' altra forza d' animo fue ornato Ponzio ...   \n",
       "3   Se questo piace a tutti e se 'l tempo hae biso...   \n",
       "4   Officio di questa arte pare che sia dicere app...   \n",
       "5   Ecco e larghi ventipiovoli caggiono delle riso...   \n",
       "6   Però che or chi spererebbe quello che eziandio...   \n",
       "7   I vendimenti de' morti et le presure de' vivi ...   \n",
       "8   Acciocché quegli, il quale ora per le sue gran...   \n",
       "9   Gli uomini spessamente a stare fermi nella bug...   \n",
       "10  Marco Cornelio ch'era de' dieci compagni, stud...   \n",
       "11       cose ch'io sapeva che erano fatte in Italia.   \n",
       "12  Corbio nipote d' Ortensio menò sua vita più ba...   \n",
       "13  Altressì uno amante chiamando merzé alla sua d...   \n",
       "14  Io mi ricordo (ch. 347) che essendo adirato sc...   \n",
       "15  colui del quale tu tti solevi dolere ch' era a...   \n",
       "16  Ma no sapeano già le nomora di coloro dela con...   \n",
       "17  Creti?  Certo quand'elli si mosse, elli ti dix...   \n",
       "18  A Milano fue ripressa la malvagità d' una donn...   \n",
       "\n",
       "                                               modern  \\\n",
       "0   Quella guerra fu condotta bene perchè etc. Dal...   \n",
       "1   È crudele, e punisce ogni colpa come vuole la ...   \n",
       "2   Ponzio Aufidiano, cavaliere romano, non fu dot...   \n",
       "3   Se questo piace a tutti e se il tempo ha bisog...   \n",
       "4   Il compito di quest’arte sembra essere quello ...   \n",
       "5   Ecco che forti piogge scendono dalle dense neb...   \n",
       "6   Perché ora chi spererebbe ciò che anche quelli...   \n",
       "7   Le vendite dei morti e le pressioni sui vivi f...   \n",
       "8    Così che colui, che ora è temuto e onorato pe...   \n",
       "9   Spesso gli uomini incontrano la verità mentre ...   \n",
       "10  Marco Cornelio, che era uno dei dieci compagni...   \n",
       "11         Cose che sapevo essere avvenute in Italia.   \n",
       "12  Corbio, nipote di Ortensio, visse una vita più...   \n",
       "13  Così anche un innamorato, chiedendo pietà alla...   \n",
       "14  Ricordo che, essendo arrabbiato, scompigliai i...   \n",
       "15  Colui di cui ti lamentavi spesso perché era in...   \n",
       "16  Ma ancora non conoscevano i nomi dei cospirato...   \n",
       "17  Credi? Certo, quando partì, ti disse: “O mia f...   \n",
       "18  A Milano fu fermata la malvagità di una donna ...   \n",
       "\n",
       "                                     tinyllama_output  \n",
       "0   la guerra che è stata effettivamente compiuta ...  \n",
       "1   crudele, e di tutte le colpe pigli vendetta, c...  \n",
       "2   Non d' altra forza d' animo fu ornato Ponzio A...  \n",
       "3   Se questo piace a tutti e se 'l tempo hae biso...  \n",
       "4   L'ufficio di questa arte sembra essere dichiar...  \n",
       "5   Ecco e larghi ventipiovoli caggiono delle riso...  \n",
       "6   Because they do not want to believe in Christ,...  \n",
       "7   I vendimenti de' morti et le presure de' vivi ...  \n",
       "8   Quegli, il quale ora è feroce e onorevole per ...  \n",
       "9   Gli uomini stanno fermi nella bugia incontrand...  \n",
       "10  Marco Cornelio, que era de diez compañeros, se...  \n",
       "11  cose che io conosco che sono state fatte in It...  \n",
       "12  Corbio nipote d'Ortensio menò la sua vita più ...  \n",
       "13  Altressì uno amante chiamando merzé alla sua d...  \n",
       "14  Io mi ricordo (ch. 347) che essendo furioso sc...  \n",
       "15  Your lover, who was in love with your wife.\\n\\...  \n",
       "16  Ma non sapevano già le nomi delle donne della ...  \n",
       "17  Credi che io sia fedele alla tua moglie, ti di...  \n",
       "18  A Milano è stata ripristinata la malvagità di ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(test_df[['ancient', 'modern', 'tinyllama_output']].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T17:37:51.744739Z",
     "iopub.status.busy": "2025-06-06T17:37:51.743953Z",
     "iopub.status.idle": "2025-06-06T17:56:26.741584Z",
     "shell.execute_reply": "2025-06-06T17:56:26.740619Z",
     "shell.execute_reply.started": "2025-06-06T17:37:51.744714Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating translations (this may take a while)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating final test set: 100%|██████████| 97/97 [18:34<00:00, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final predictions saved to /kaggle/working/tinyllama_final_dataset_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 13. Process final_test_set_path (dataset.csv) and save with new columns --\n",
    "\n",
    "final_output_test_file_path = '/kaggle/input/dataset-list/dataset.csv'\n",
    "\n",
    "final_test_df = pd.read_csv(final_output_test_file_path)\n",
    "ancient_text_column_name = 'Sentence'\n",
    "\n",
    "final_test_df[ancient_text_column_name] = final_test_df[ancient_text_column_name].apply(fix_list_string_to_sentence)\n",
    "    \n",
    "# Filter out any empty sentences after cleaning, if any\n",
    "final_test_df = final_test_df[final_test_df[ancient_text_column_name].str.strip() != \"\"].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "# Get the list of ancient sentences to translate\n",
    "ancient_sentences_to_translate = final_test_df[ancient_text_column_name].tolist()\n",
    "\n",
    "model.eval()\n",
    "generated_translations = []\n",
    "print(\"Generating translations (this may take a while)...\")\n",
    "for text in tqdm(ancient_sentences_to_translate, desc=\"Translating final test set\"):\n",
    "    generated_translations.append(generate_with_tinyllama(text))\n",
    "final_test_df['generated_translation'] = generated_translations\n",
    "final_test_df['score_human'] = 0\n",
    "output_csv_path = \"/kaggle/working/tinyllama_final_dataset_predictions.csv\"\n",
    "output_columns = ['Author', 'Date', 'Region', 'Sentence', 'generated_translation', 'score_human']\n",
    "\n",
    "final_output_df_columns = [col for col in output_columns if col in final_test_df.columns]\n",
    "if 'generated_translation' not in final_output_df_columns:\n",
    "    final_output_df_columns.append('generated_translation')\n",
    "if 'score_human' not in final_output_df_columns:\n",
    "    final_output_df_columns.append('score_human')\n",
    "\n",
    "final_test_df[final_output_df_columns].to_csv(output_csv_path, index=False)\n",
    "print(f\"Final predictions saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7603016,
     "sourceId": 12077999,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
